{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring your trained model\n",
    "\n",
    "In the cell below, please load your model into `model`. Also if you used an image size for your input images that *isn't* 224x224, you'll need to set `image_size` to the size you used. The scoring code assumes square input images.\n",
    "\n",
    "For example, this is how I loaded in my checkpoint:\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "class FFClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_features, hidden_features, \n",
    "                       out_features, drop_prob=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(p=drop_prob)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.drop(F.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def load_checkpoint(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    \n",
    "    model = models.vgg16(pretrained=False)\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # Put the classifier on the pretrained network\n",
    "    model.classifier = FFClassifier(25088, checkpoint['hidden'], 102)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = load_checkpoint('/home/workspace/classifier.pt')\n",
    "```\n",
    "\n",
    "Your exact code here will depend on how you defined your network in the project. Make sure you use the absolute path to your checkpoint which should have been uploaded to the `/home/workspace` directory.\n",
    "\n",
    "Run the cell, then after loading the data, press \"Test Code\" below. This can take a few minutes or more depending on the size of your network. Your model needs  to reach **at least 20% accuracy** on the test set to be recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown==3.6.0\n",
      "  Downloading https://files.pythonhosted.org/packages/12/33/e9f21d0b3f85804ca570d124fb7a80c12a99948ff495cf54dfb72f18bf9e/gdown-3.6.0.tar.gz\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from gdown==3.6.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from gdown==3.6.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from gdown==3.6.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->gdown==3.6.0)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->gdown==3.6.0)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->gdown==3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->gdown==3.6.0)\n",
      "Building wheels for collected packages: gdown\n",
      "  Running setup.py bdist_wheel for gdown ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/97/90/fa/25654eb65da3e6da7752db71a164e0eb8f7a6fb4335eeb46ab\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-3.6.0\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown==3.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1xIgZQknlp3IIa5jsgBoINp9rpF0JiUGe\n",
      "To: /home/workspace/model_checkpoint_B_2019-01-09 15:10:53.pt\n",
      "234MB [00:01, 145MB/s]  \n"
     ]
    }
   ],
   "source": [
    "my_file_id = \"1xIgZQknlp3IIa5jsgBoINp9rpF0JiUGe\" # https://drive.google.com/file/d/1xIgZQknlp3IIa5jsgBoINp9rpF0JiUGe/view?usp=sharing\n",
    "!gdown https://drive.google.com/uc?id={my_file_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "vriua3cwbv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "# Classifier class coded to work like the example above.\n",
    "class FFClassifier(nn.Module):\n",
    "    def __init__(self, in_features, hidden_1, hidden_2, \n",
    "                 out_features, drop_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_features, out_features)\n",
    "        \n",
    "        #self.fc1 = nn.Linear(in_features, hidden_1)\n",
    "        #self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        #self.fc3 = nn.Linear(hidden_2, out_features)\n",
    "        #self.drop = nn.Dropout(p=drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        #x = self.drop(F.relu(self.fc1(x)))\n",
    "        #x = self.drop(F.relu(self.fc2(x)))\n",
    "        #x = self.fc3(x)\n",
    "        \n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    model = models.resnet152(pretrained=False)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "       param.requires_grad = False\n",
    "\n",
    "    # Put the classifier on the pretrained network\n",
    "    model.fc = FFClassifier(2048, \n",
    "                                    checkpoint['hidden_1'], \n",
    "                                    checkpoint['hidden_2'], \n",
    "                                    102, \n",
    "                                    drop_prob=0.2)\n",
    "\n",
    "    model.load_state_dict(checkpoint['state_dict'], strict=False)\n",
    "\n",
    "    model.class_to_idx = checkpoint[\"class_to_idx\"]\n",
    "    model.idx_to_class = checkpoint[\"idx_to_class\"]\n",
    "    model.cat_to_name = checkpoint[\"cat_to_name\"]\n",
    "    model.hidden_1 = checkpoint[\"hidden_1\"]\n",
    "    model.hidden_2 = checkpoint[\"hidden_2\"]\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Load the model\n",
    "model = load_checkpoint('/home/workspace/model_checkpoint_B_2019-01-09 15:10:53.pt')\n",
    "#model = load_checkpoint('/home/workspace/model_checkpoint_C_2019-01-09 15:20:57.pt')\n",
    "   \n",
    "# If you used something other than 224x224 cropped images, set the correct size here\n",
    "image_size = 224\n",
    "\n",
    "# Values you used for normalizing the images. Default here are for \n",
    "# pretrained models from torchvision.\n",
    "\n",
    "# norm_mean = [0.485, 0.456, 0.406]\n",
    "# norm_std = [0.229, 0.224, 0.225]\n",
    "norm_mean = [0.5178361839861569, 0.4106749456881299, 0.32864167836880803]\n",
    "norm_std = [0.2972239085211309, 0.24976049135203868, 0.28533308036347665]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'deep-learning-flower-identifier' already exists and is not an empty directory.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting airtable\n",
      "  Downloading https://files.pythonhosted.org/packages/a8/ef/8b2bee11988bb1b4df41454a999f855bd568a74b8b58fd92279bfb50fb56/airtable-0.3.1.tar.gz\n",
      "Requirement already satisfied: requests>=2.5.3 in /opt/conda/lib/python3.6/site-packages (from airtable)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests>=2.5.3->airtable)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests>=2.5.3->airtable)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests>=2.5.3->airtable)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests>=2.5.3->airtable)\n",
      "Building wheels for collected packages: airtable\n",
      "  Running setup.py bdist_wheel for airtable ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9b/ba/63/364c02fabcd50ef6e2f101a57feb727bd7a693697765a9df17\n",
      "Successfully built airtable\n",
      "Installing collected packages: airtable\n",
      "Successfully installed airtable-0.3.1\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Mean accuracy: 0.9939903616905212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99399036"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/GabrielePicco/deep-learning-flower-identifier\n",
    "\n",
    "!git clone https://github.com/GabrielePicco/deep-learning-flower-identifier\n",
    "!pip install requests\n",
    "!pip install airtable\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, 'deep-learning-flower-identifier')\n",
    "from test_model_pytorch_facebook_challenge import calc_accuracy\n",
    "\n",
    "# model = load_your_model('classifier.pth')\n",
    "calc_accuracy(model, input_image_size=224, use_google_testset=False, norm_mean=norm_mean, norm_std=norm_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data option 2 - Download train + validation + testing data\n",
    "\n",
    "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/nd089/flower_data.tar.gz\n",
    "!rm -rf flower_data\n",
    "!mkdir flower_data\n",
    "!tar -xzf \"flower_data.tar.gz\" --directory flower_data\n",
    "\n",
    "# Correct misslabelled valid data.\n",
    "!mv flower_data/valid/93/image_07303.jpg flower_data/valid/94\n",
    "!mv flower_data/valid/96/image_07677.jpg flower_data/valid/97\n",
    "\n",
    "# Correct misslabelled test data.\n",
    "!mv flower_data/test/96/image_07683.jpg flower_data/test/97\n",
    "!mv flower_data/test/96/image_07676.jpg flower_data/test/97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load some data for testing the loaded model.\n",
    "\n",
    "import time\n",
    "import math\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "data_dir = 'flower_data'\n",
    "#final_test_dir = data_dir + '/valid'\n",
    "final_test_dir = data_dir + '/test'\n",
    "\n",
    "data_transforms = {'final_test': transforms.Compose([transforms.Resize(256, interpolation=2),\n",
    "                                                #===\n",
    "                                                transforms.CenterCrop(224),\n",
    "                                                #===\n",
    "                                                # transforms.Grayscale(num_output_channels=3),\n",
    "                                                transforms.ToTensor(),\n",
    "                                                transforms.Normalize(norm_mean, \n",
    "                                                                     norm_std),\n",
    "                                               ])\n",
    "                  }\n",
    "\n",
    "# Load the datasets with ImageFolder\n",
    "image_datasets = {'final_test': datasets.ImageFolder(final_test_dir, transform=data_transforms['final_test'])}\n",
    "\n",
    "# Using the image datasets and the trainforms, define the dataloaders\n",
    "batch_size = 4\n",
    "\n",
    "dataloaders = {'final_test': torch.utils.data.DataLoader(image_datasets['final_test'], batch_size=batch_size, shuffle=True)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <progress\n",
       "            value='33.65853658536585'\n",
       "            max='100',\n",
       "            style='width: 100%'\n",
       "        >\n",
       "            33.65853658536585\n",
       "        </progress>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the loaded model.\n",
    "\n",
    "def progress_bar(value, max=100):\n",
    "    return HTML(\"\"\"\n",
    "        <progress\n",
    "            value='{value}'\n",
    "            max='{max}',\n",
    "            style='width: 100%'\n",
    "        >\n",
    "            {value}\n",
    "        </progress>\n",
    "    \"\"\".format(value=value, max=max))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "test_loss_sum = 0.0\n",
    "test_correct_count = 0.0\n",
    "\n",
    "######################    \n",
    "# test the model #\n",
    "######################\n",
    "test_start_time = time.time()\n",
    "print(\"Testing...\")\n",
    "test_display = display(progress_bar(0, 100), display_id=True)\n",
    "\n",
    "model.eval()    \n",
    "num_batches = math.ceil(len(dataloaders['final_test'].dataset) / batch_size)\n",
    "batch_stride = 1\n",
    "\n",
    "for batch_idx, (images, labels) in enumerate(dataloaders['final_test']):\n",
    "    if batch_idx % batch_stride == 0:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(images)  # batch_size x 102\n",
    "            loss = criterion(outputs, labels)  # Average loss value over batch# .\n",
    "\n",
    "        test_loss_sum += loss.item() * images.size(0)\n",
    "\n",
    "        _, predicted_labels = torch.max(outputs, -1)\n",
    "        test_correct_count += (predicted_labels == labels).double().sum().item()\n",
    "\n",
    "        progress = (batch_idx+1) * 100.0 / num_batches\n",
    "        test_display.update(progress_bar(progress, 100))\n",
    "\n",
    "\n",
    "test_end_time = time.time()\n",
    "\n",
    "############################\n",
    "# calculate average losses #\n",
    "############################\n",
    "test_loss = test_loss_sum * batch_stride / len(dataloaders['final_test'].dataset)\n",
    "test_acc = test_correct_count * batch_stride / len(dataloaders['final_test'].dataset)\n",
    "\n",
    "print('Testing Loss={:.6f}  Testing Accuracy={:.6f}  Duration={:.2f}'.format(test_loss, \n",
    "                                                                             test_acc, \n",
    "                                                                             test_end_time - test_start_time))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "cell_exec_timeout": 600,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
